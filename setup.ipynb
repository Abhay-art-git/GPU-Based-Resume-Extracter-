# Cell 7: Create setup.py for Colab
setup_code = '''
import subprocess
import sys
import os

def setup_colab_environment():
    """Setup everything needed for GPU resume extraction."""

    print("Setting up Resume Extractor on Google Colab GPU...")
    print("="*60)

    # 1. Check GPU
    import torch
    if torch.cuda.is_available():
        print(f"✓ GPU detected: {torch.cuda.get_device_name(0)}")
    else:
        print("⚠ No GPU detected! Performance will be limited.")

    # 2. Start Ollama service
    print("\\nStarting Ollama service...")
    subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    import time
    time.sleep(5)

    # 3. Pull model with GPU support
    print("\\nPulling Mistral model for GPU...")
    result = subprocess.run(['ollama', 'pull', 'mistral:7b-instruct'], capture_output=True, text=True)
    if result.returncode == 0:
        print("✓ Model ready for GPU inference")
    else:
        print(f"⚠ Model pull issue: {result.stderr}")

    # 4. Test GPU inference
    print("\\nTesting GPU inference...")
    import ollama
    try:
        response = ollama.chat(
            model='mistral:7b-instruct',
            messages=[{'role': 'user', 'content': 'test'}],
            options={'num_gpu': 999}
        )
        print("✓ GPU inference working!")
    except Exception as e:
        print(f"⚠ GPU inference test failed: {e}")

    # 5. Download NLTK data
    print("\\nDownloading NLTK data...")
    import nltk
    nltk.download('stopwords', quiet=True)
    nltk.download('punkt', quiet=True)
    print("✓ NLTK data ready")

    print("\\n" + "="*60)
    print("✓ SETUP COMPLETE - Ready for GPU-accelerated extraction!")
    print("="*60)

    return True

if __name__ == "__main__":
    setup_colab_environment()
'''

with open('setup.py', 'w') as f:
    f.write(setup_code)
print("✓ Created setup.py")
